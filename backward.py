# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WFBB3GkWmq85AnJdARz1cldePl9Xo6gX
"""

import torch
import torch.nn as nn
import numpy as np
N_grid = 21
c = 299792458
D = 1e-4
x_min, x_max = 0, 0.1
y_min, y_max = 0, 0.1
z_min, z_max = 0, 0.1
t_min, t_max = 0, 1e-9
device = 'cuda' if torch.cuda.is_available() else 'cpu'
class MuNet(nn.Module):
    def __init__(self):
        super(MuNet, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(3, 50),   # 输入：x, y, z
            nn.Softplus(),
            nn.Linear(50, 50),
            nn.Softplus(),
            nn.Linear(50, 50),
            nn.Softplus(),
            nn.Linear(50, 50),
            nn.Softplus(),
            nn.Linear(50, 1),
            nn.Softplus()       # 确保输出 μₐ ≥ 0
        )

    def forward(self, x):
        return self.net(x)*1000+9.9

class PhiNet(nn.Module):
    def __init__(self):
        super(PhiNet, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(4, 50),   # 输入：x, y, z, t
            nn.Softplus(),
            nn.Linear(50, 50),
            nn.Softplus(),
            nn.Linear(50, 50),
            nn.Softplus(),
            nn.Linear(50, 50),
            nn.Softplus(),
            nn.Linear(50, 50),
            nn.Softplus(),
            nn.Linear(50, 50),
            nn.Softplus(),
            nn.Linear(50, 1),
            nn.Softplus()     # 确保输出 φ ≥ 0
        )

    def forward(self, x):
        return self.net(x)

def train_on_batch(phi_net, mu_net, phi_boundary_data, num_epochs=1000, ss=1):

    """
    在单个批次的数据上训练 PhiNet，并更新 MuNet 的参数。

    参数：
        mu_net: 共享的 MuNet 实例。
        phi_boundary_data: 包含边界采样点和对应测量数据的字典。
        num_epochs: 训练轮数。
    """


    # 将 mu_net 和 phi_net 的参数组合
    paramsphi = list(phi_net.parameters())
    optimizerphi = torch.optim.NAdam(paramsphi, lr=1e-4)
    paramsmu = list(mu_net.parameters())
    optimizermu = torch.optim.NAdam(paramsmu, lr=1e-3)

    # 从 phi_boundary_data 中获取边界采样点和测量数据
    x_b = phi_boundary_data['x_b'].to(device).requires_grad_(True)
    y_b = phi_boundary_data['y_b'].to(device).requires_grad_(True)
    z_b = phi_boundary_data['z_b'].to(device).requires_grad_(True)
    t_b = phi_boundary_data['t_b'].to(device).requires_grad_(True)
    phi_data_b = phi_boundary_data['phi_data_b'].to(device).requires_grad_(True)

    # 内部采样点（可以在每个批次中重新生成）
    N_f = 20000
    x_f = torch.FloatTensor(N_f, 1).uniform_(x_min, x_max).to(device).requires_grad_(True)
    y_f = torch.FloatTensor(N_f, 1).uniform_(y_min, y_max).to(device).requires_grad_(True)
    z_f = torch.FloatTensor(N_f, 1).uniform_(z_min, z_max).to(device).requires_grad_(True)
    t_f = torch.FloatTensor(N_f, 1).uniform_(t_min, t_max).to(device).requires_grad_(True)
    xx = x_f.clone().detach().requires_grad_(True)
    yy = y_f.clone().detach().requires_grad_(True)
    zz = z_f.clone().detach().requires_grad_(True)
    tt = t_f.clone().detach().requires_grad_(True)

    lossfomer = 1e99
    epoch = 0
    # 训练循环
    while 1:
        epoch += 1
        optimizerphi.zero_grad()
        optimizermu.zero_grad()



        # 边界采样点
        inputs_b = torch.cat([x_b, y_b, z_b, t_b], dim=1).to(device).requires_grad_(True)  # (N_b, 4)

        # 预测边界上的 φ
        phi_b_pred = phi_net(inputs_b)  # (N_b, 1)


        loss_bc = torch.mean(((phi_b_pred - phi_data_b)*1e4) ** 4)

        # 内部点的计算（同上）
        # 内部采样点
        inputs_f = torch.cat([x_f, y_f, z_f, t_f], dim=1)  # (N_f, 4)
        r_f = torch.cat([xx, yy, zz], dim=1)            # (N_f, 3)

        # 预测 φ
        phi = phi_net(inputs_f)      # (N_f, 1)

        # 预测 μₐ
        mu_a_pred = mu_net(r_f)      # (N_f, 1)
        # ...
        # 时间导数 ∂φ/∂t
        phi_t = torch.autograd.grad(phi, t_f, torch.ones_like(phi), create_graph=True)[0]

        # 空间二阶导数 ∇²φ
        phi_x = torch.autograd.grad(phi, x_f, torch.ones_like(phi), create_graph=True)[0]
        phi_xx = torch.autograd.grad(phi_x, x_f, torch.ones_like(phi_x), create_graph=True)[0]

        phi_y = torch.autograd.grad(phi, y_f, torch.ones_like(phi), create_graph=True)[0]
        phi_yy = torch.autograd.grad(phi_y, y_f, torch.ones_like(phi_y), create_graph=True)[0]

        phi_z = torch.autograd.grad(phi, z_f, torch.ones_like(phi), create_graph=True)[0]
        phi_zz = torch.autograd.grad(phi_z, z_f, torch.ones_like(phi_z), create_graph=True)[0]

        # 拉普拉斯算子 ∇²φ
        laplace_phi = phi_xx + phi_yy + phi_zz
        #print(laplace_phi)

        # PDE 残差
        f_pde = phi_t - c * (D * laplace_phi - mu_a_pred * phi)

        # PDE 残差的 MSE 损失
        loss_pde = torch.mean(f_pde ** 2)
        # if ss == 1:
        #   input_s = torch.tensor([0.05, 0.05, 0, 0], requires_grad=True).to(device)
        # elif ss == 2:
        #   input_s = torch.tensor([0.033333, 0.0333333, 0, 0], requires_grad=True).to(device)
        # elif ss == 3:
        #   input_s = torch.tensor([0, 0.05, 0.05, 0], requires_grad=True).to(device)
        # elif ss == 4:
        #   input_s = torch.tensor([0, 0.025, 0.025, 0], requires_grad=True).to(device)
        # phi_s = phi_net(input_s)
        # target = torch.tensor([1e3]).to(device)  # 不需要 requires_grad

        # loss_s = (phi_s - target) ** 2
        # 计算损失
        if epoch % 10 == 1:
          loss = loss_bc + loss_pde
        else:
          loss = loss_bc
        #loss = (torch.mean(mu_a_pred)-57.1238)**4#+ loss_s
        #loss = loss_s


        # 打印损失
        if epoch % 10 == 1:
            print(f"Epoch {epoch}, Loss: {loss.item()}, PDE Loss: {loss_pde.item()}, BC Loss: {loss_bc.item()}")
            #print(phi_b_pred)
        if lossfomer <= loss and epoch>3000 or epoch>3000:
          break
        lossfomer = loss

        # 反向传播和优化
        loss.backward()
        optimizerphi.step()
        optimizermu.step()
    return mu_net  # 返回更新后的 mu_net

def trilinear_interpolation(data, x, y, z):
    """
    在三维数据中对给定的坐标进行三线性插值。

    参数：
        data: 形状为 (N_grid, N_grid, N_grid) 的三维数组。
        x, y, z: 连续的坐标，范围在 [0, N_grid - 1] 之间。

    返回：
        插值后的值。
    """
    x0 = int(np.floor(x))
    x1 = x0 + 1
    y0 = int(np.floor(y))
    y1 = y0 + 1
    z0 = int(np.floor(z))
    z1 = z0 + 1

    # 边界检查
    x0 = np.clip(x0, 0, N_grid - 1)
    x1 = np.clip(x1, 0, N_grid - 1)
    y0 = np.clip(y0, 0, N_grid - 1)
    y1 = np.clip(y1, 0, N_grid - 1)
    z0 = np.clip(z0, 0, N_grid - 1)
    z1 = np.clip(z1, 0, N_grid - 1)

    xd = x - x0
    yd = y - y0
    zd = z - z0

    # 获取8个顶点的值
    c000 = data[x0, y0, z0]
    c001 = data[x0, y0, z1]
    c010 = data[x0, y1, z0]
    c011 = data[x0, y1, z1]
    c100 = data[x1, y0, z0]
    c101 = data[x1, y0, z1]
    c110 = data[x1, y1, z0]
    c111 = data[x1, y1, z1]

    # 三线性插值公式
    c00 = c000 * (1 - xd) + c100 * xd
    c01 = c001 * (1 - xd) + c101 * xd
    c10 = c010 * (1 - xd) + c110 * xd
    c11 = c011 * (1 - xd) + c111 * xd

    c0 = c00 * (1 - yd) + c10 * yd
    c1 = c01 * (1 - yd) + c11 * yd

    c = c0 * (1 - zd) + c1 * zd

    return c

def phi_boundary_data(x_b, y_b, z_b, t_b, data_folder):
    """
    根据输入的边界采样点坐标和对应的批次数据文件夹，返回对应的 phi 测量值。

    参数：
        x_b, y_b, z_b: 边界采样点的坐标，形状为 (N_b, 1)，单位：米
        t_b: 时间点，形状为 (N_b, 1)，单位：秒
        data_folder: 字符串，指定数据文件夹的路径

    返回：
        phi_data_b: 对应的 phi 测量值，形状为 (N_b, 1)
    """
    import os
    import numpy as np
    import torch

    N_b = x_b.shape[0]
    phi_data_b = []

    # 获取文件夹中的时间点和文件名映射
    time_to_filename = get_time_to_filename_mapping(data_folder)
    time_points = sorted(time_to_filename.keys())
    N_grid = 21  # 网格尺寸
    L = 0.1      # 立方体边长，米

    for i in range(N_b):
        x = x_b[i].item()
        y = y_b[i].item()
        z = z_b[i].item()
        t = t_b[i].item()

        # 将 (x, y, z) 映射到数组索引（连续值）
        x_normalized = (x / L) * (N_grid - 1)
        y_normalized = (y / L) * (N_grid - 1)
        z_normalized = (z / L) * (N_grid - 1)

        # 找到相邻的时间点
        time_keys = np.array(time_points)
        idx_time = np.searchsorted(time_keys, t)

        if idx_time == 0 or idx_time == len(time_keys):
            # t 超出时间范围，使用最近的时间点
            nearest_time = time_keys[np.argmin(np.abs(time_keys - t))]
            filename = time_to_filename[nearest_time]

            # 加载数据
            data = np.load(os.path.join(data_folder, filename))

            # 使用三线性插值
            phi_value = trilinear_interpolation(data, x_normalized, y_normalized, z_normalized)
        else:
            # t 在两个时间点之间，进行时间线性插值
            t0 = time_keys[idx_time - 1]
            t1 = time_keys[idx_time]

            filename0 = time_to_filename[t0]
            filename1 = time_to_filename[t1]

            data0 = np.load(os.path.join(data_folder, filename0))
            data1 = np.load(os.path.join(data_folder, filename1))

            # 使用三线性插值
            phi_value0 = trilinear_interpolation(data0, x_normalized, y_normalized, z_normalized)
            phi_value1 = trilinear_interpolation(data1, x_normalized, y_normalized, z_normalized)

            # 时间线性插值
            phi_value = ((t1 - t) * phi_value0 + (t - t0) * phi_value1) / (t1 - t0)

        phi_data_b.append(phi_value)

    # 转换为张量
    phi_data_b = torch.tensor(phi_data_b, dtype=torch.float32).view(-1, 1)
    return phi_data_b

def get_time_to_filename_mapping(folder):
    """
    返回指定文件夹中的时间与文件名的映射关系。

    参数：
        folder: 数据文件夹路径

    返回：
        time_to_filename: 字典，键为时间点（浮点数），值为文件名
    """
    import os
    import numpy as np

    # 获取文件列表
    files = os.listdir(folder)
    # 只保留 .npy 文件
    files = [f for f in files if f.endswith('.npy')]

    # 提取文件编号并排序
    file_indices = [int(os.path.splitext(f)[0][4:]) for f in files]

    file_indices.sort()

    # 建立时间与文件名的映射
    time_step = 1e-11  # 时间步长
    time_to_filename = {}
    for idx in file_indices:
        time = idx * time_step  # 计算时间
        filename = f"{idx}.npy"
        time_to_filename[time] = filename
    return time_to_filename

# 初始化 MuNet
mu_net = MuNet().to(device)

def create_boundary_data_from_npy(npy_file, x_min, x_max, y_min, y_max, z_min, z_max, t_min, t_max, N_b=5000):
    # Load the data
    data = np.load(npy_file)  # Shape: (X, Y, Z, T)
    X_dim, Y_dim, Z_dim, T_dim = data.shape
    #print(X_dim,Y_dim,Z_dim,T_dim)
    # Create coordinate arrays
    x_values = np.linspace(x_min, x_max, X_dim)
    y_values = np.linspace(y_min, y_max, Y_dim)
    z_values = np.linspace(z_min, z_max, Z_dim)
    t_values = np.linspace(t_min, T_dim*1e-11, T_dim)

    # Define boundary indices
    x_boundary_indices = [0, X_dim - 1]
    y_boundary_indices = [0, Y_dim - 1]
    z_boundary_indices = [0, Z_dim - 1]

    # Collect boundary indices
    boundary_indices = set()

    # x boundaries
    for xi in x_boundary_indices:
        for yi in range(Y_dim):
            for zi in range(Z_dim):
                for ti in range(T_dim):
                    boundary_indices.add((xi, yi, zi, ti))

    # y boundaries
    for yi in y_boundary_indices:
        for xi in range(X_dim):
            for zi in range(Z_dim):
                for ti in range(T_dim):
                    boundary_indices.add((xi, yi, zi, ti))
    # z boundaries
    for zi in z_boundary_indices:
        for xi in range(X_dim):
            for yi in range(Y_dim):
                for ti in range(T_dim):
                    boundary_indices.add((xi, yi, zi, ti))

    boundary_indices = list(boundary_indices)

    # Randomly sample N_b indices
    import random
    if N_b > len(boundary_indices):
        N_b = len(boundary_indices)
    sampled_indices = random.sample(boundary_indices, N_b)

    # Initialize lists to collect boundary data
    x_b_list, y_b_list, z_b_list, t_b_list, phi_data_b_list = [], [], [], [], []

    for (xi, yi, zi, ti) in sampled_indices:
        x_b_list.append(x_values[xi])
        y_b_list.append(y_values[yi])
        z_b_list.append(z_values[zi])
        t_b_list.append(t_values[ti])
        phi_data_b_list.append(data[xi, yi, zi, ti])


    # Convert lists to torch tensors
    x_b = torch.tensor(x_b_list, dtype=torch.float32).unsqueeze(1).requires_grad_(True)
    y_b = torch.tensor(y_b_list, dtype=torch.float32).unsqueeze(1).requires_grad_(True)
    z_b = torch.tensor(z_b_list, dtype=torch.float32).unsqueeze(1).requires_grad_(True)
    t_b = torch.tensor(t_b_list, dtype=torch.float32).unsqueeze(1).requires_grad_(True)
    phi_data_b = torch.tensor(phi_data_b_list, dtype=torch.float32).unsqueeze(1).requires_grad_(True)

    # Return the boundary data in the required format
    #print(x_b,y_b,z_b,t_b,phi_data_b)
    return {
        'x_b': x_b,
        'y_b': y_b,
        'z_b': z_b,
        't_b': t_b,
        'phi_data_b': phi_data_b
    }

# Now, apply this function to your two .npy files
data_folder = 'path_to_your_data_folder'  # Specify the path to your data folder
npy_file1 = f"/content/combined_array.npy"
npy_file2 = f"/content/combined_array1.npy"
npy_file3 = f"/content/combined_array2.npy"
npy_file4 = f"/content/combined_array3.npy"

# Generate boundary data for each dataset
# boundary_data1 = create_boundary_data_from_npy(npy_file1, x_min, x_max, y_min, y_max, z_min, z_max, t_min, t_max)
# boundary_data2 = create_boundary_data_from_npy(npy_file2, x_min, x_max, y_min, y_max, z_min, z_max, t_min, t_max)

# Now, create your PhiNet instances
phi_net1 = PhiNet().to(device)
phi_net2 = PhiNet().to(device)
phi_net3 = PhiNet().to(device)
phi_net4 = PhiNet().to(device)
# phi_net1.load_state_dict(torch.load('/content/phi_net1_epoch_30.pth'))
# phi_net2.load_state_dict(torch.load('/content/phi_net2_epoch_30.pth'))
# phi_net3.load_state_dict(torch.load('/content/phi_net3_epoch_30.pth'))
# phi_net4.load_state_dict(torch.load('/content/phi_net4_epoch_30.pth'))

# Train your models using the extracted boundary data
for i in range(1000000):
  boundary_data1 = create_boundary_data_from_npy(npy_file1, x_min, x_max, y_min, y_max, z_min, z_max, t_min, t_max)
  boundary_data2 = create_boundary_data_from_npy(npy_file2, x_min, x_max, y_min, y_max, z_min, z_max, t_min, t_max)
  boundary_data3 = create_boundary_data_from_npy(npy_file3, x_min, x_max, y_min, y_max, z_min, z_max, t_min, t_max)
  boundary_data4 = create_boundary_data_from_npy(npy_file4, x_min, x_max, y_min, y_max, z_min, z_max, t_min, t_max)
  print("Training on boundary data from data1.npy")
  mu_net = train_on_batch(phi_net1, mu_net, boundary_data1, num_epochs=50, ss = 1)

  print("Training on boundary data from data2.npy")
  mu_net = train_on_batch(phi_net2, mu_net, boundary_data2, num_epochs=50, ss = 2)

  print("Training on boundary data from data3.npy")
  mu_net = train_on_batch(phi_net3, mu_net, boundary_data3, num_epochs=50, ss = 3)

  print("Training on boundary data from data4.npy")
  mu_net = train_on_batch(phi_net4, mu_net, boundary_data4, num_epochs=50, ss = 4)
  if i % 5 == 0:
    torch.save(mu_net.state_dict(), f'mu_net_epoch_{i}.pth')
    torch.save(phi_net1.state_dict(), f'phi_net1_epoch_{i}.pth')
    torch.save(phi_net2.state_dict(), f'phi_net2_epoch_{i}.pth')
    torch.save(phi_net3.state_dict(), f'phi_net3_epoch_{i}.pth')
    torch.save(phi_net4.state_dict(), f'phi_net4_epoch_{i}.pth')